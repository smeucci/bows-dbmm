\section{Image representation}

In BoW model each image is represented as a histogram of \emph{visual words} occurrences through local descriptor quantization\cite{DBLP:journals/corr/abs-1304-5168}. These histograms are used to train an image classifier.

To quantize local descriptors into visual words, we must first generate a visual vocabulary. 

\subsection{Vocabulary creation}

The visual vocabulary for BoW model is often generated by clustering of images local descriptors. In this case we used \emph{k-means} algorithm as clustering method.

This algorithm iteratively groups the descriptors into $k$ mutually exclusive clusters, where $k$ is the preset \emph{vocabulary size}. The resulting cluster are compact and separated by similar characteristics so they are treated as a unique visual word from the vocabulary, in which the \emph{codewords} are represented by the centroids of the clusters.

\subsection{Feature quantization}

Feature quantization is the process of assigning one local descriptor to one or multiple
visual words. To assign a descriptor to visual word(s) there are two way to proceed: \emph{hard assignment} or \emph{soft assignment}.

\subsubsection{Hard assignment}

A simple way to assign a descriptor to a visual word is to search for nearest neighbors among the vocabulary.

Let $V = \{\omega_1, \ldots, \omega_p \}$ be the vocabulary, where $\omega_i \in \mathbb{R}^{d}$ (with $d$ the SIFT descriptor vector size, 128) and $p$ is the vocabulary size.

In \emph{hard assignment}, given and image with $X = \{x_1, \ldots, x_n\}$ extracted local features, each local feature $x_i \in \mathbb{R}^{d}$ is assigned to one and only one codeword of the vocabulary. For each $\omega \in V$:
\begin{equation}
CB(\omega) = \frac{1}{n} \sum_{i = 1}^{n} \left\{
\begin{array}{rl}
1 & \mbox{if } \omega = arg \min_{v \in V} d(v, x_i) \\
0 & \mbox{otherwise}
\end{array}
\right.
\end{equation}

\subsubsection{Soft assignment}

The \emph{hard assignment} method does not consider codeword ambiguity and often introduces large quantization error. Those two issues are known as \emph{codeword uncertainty} and \emph{codeword plausibility}. 

Codeword uncertainty refers to the problem of selecting the correct codeword out of two or more relevant candidates. The \emph{hard assignment} approach merely selects the best representing codeword, ignoring the relevance of other candidates. 

Codeword plausibility denotes the problem of selecting a codeword without a suitable candidate in the vocabulary. The \emph{hard assignment} approach assigns the best fitting codeword, regardless the fact that this codeword is not a proper representative\cite{Gemert:2008:KCS:1478172.1478227}. 

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.35\textwidth]{images/soft-assignment.jpg}
\end{center}
  \caption{Voronoi segmentation of the features space}
\label{fig:softAssignment}
\end{figure}

Figure \ref{fig:softAssignment} illustrates both these problems. The small dots represent image features, the labeled red circles are the visual words. The yellow triangle represents a data sample that is well suited to the hard assignment approach. The difficulty with codeword uncertainty is shown by the square, and the problem of codeword plausibility is illustrated by the diamond.

\emph{Soft assignment} coding is proposed to alleviate those drawbacks by assigning a local feature to all visual words. The coding coefficient represents the membership of a local feature to different visual words.

\paragraph{Kernel Codebook}

In Kernel Codebook approach we apply techniques from kernel density estimation to allow a degree of ambiguity in assigning codewords to image features. 

For each codeword $\omega$ we evaluate
\begin{equation}
KCB(\omega) = \frac{1}{n} \sum_{i = 1}^{n} K_{\sigma}(d(\omega, x_i))
\end{equation}
where $n$ is the number of local features, $x_i$ is the local feature $i$ and $K_{\sigma}$ is the kernel function defined as
\begin{equation}
K_{\sigma} (x) = \frac{1}{\sqrt{2\pi} \sigma} e^{- \frac{1}{2} \frac{x^2}{\sigma^2}}
\end{equation}
In essence, Kernel Codebook smoothes the hard mapping of features in an image region to the codeword vocabulary.

\paragraph{Codeword uncertainty}

Codeword uncertainty indicates that one image region may distribute probability mass to more than one codeword.
\begin{equation}
UNC(\omega) = \frac{1}{n} \sum_{i = 1}^{n} \frac{K_{\sigma}(d(\omega, x_i))}{\sum_{j=1}^{|V|} K_{\sigma}(d(\omega_j, x_i))}
\end{equation}

\paragraph{Localized soft assignment}

The \emph{localized soft assignment} approach is proposed in \cite{LingqiaoLiu:2011:DSC:2355573.2356438}. Instead of evaluate each distance between a local feature and all the visual words,  we consider only a subset of codewords. Specifically, for each local feature $x_i$ 
\begin{equation}
\hat{d}(x_i, \omega_j) =
\left\{
\begin{array}{ll}
d(x_i, \omega_j) & \mbox{if } \omega_j \in \mathcal{N}_k(x_i) \\
\infty & \mbox{otherwise}
\end{array}
\right.
\end{equation}
where $\mathcal{N}_k$ is the set of the $k$ nearest visual words at $x_i$. At this point we can use codeword uncertainty with $\hat{d}$ as distances.

\subsection{Bag of Feature representation}

After the feature quatization step (with hard or soft assignment) each image is represented by a histogram in which each bin represents the probability of the corresponding codeword in the image.



