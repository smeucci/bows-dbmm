\section{Image representation}

In BoW model each image is represented as a histogram of \emph{visual words} occurrences through local descriptor quantization\cite{DBLP:journals/corr/abs-1304-5168}. These histograms are used to train an image category classifier.

To quantize local descriptors into visual words, we must first generate visual vocabulary. 

\subsection{Vocabulary creation}

The visual vocabulary for BoW model is often generated by clustering of images local descriptors. In this case we \emph{k-means} algorithm as clustering method.

This algorithm iteratively groups the descriptors into $k$ mutually exclusive clusters, where $k$ is the preset \emph{vocabulary size}. The resulting cluster are compact and separated by similar characteristics so they are trated as a unique visual word from the vocabulary, in which each \emph{codeword} is represented by the centroid of the cluster.

\subsection{Feature quantization}

Feature quantization is the process of assigning one local descriptor to one or multiple
visual words. To assign a descriptor to visual word(s) there are two way to proceed: \emph{hard assignment} or \emph{soft assignment}.

\subsubsection{Hard assignment}

A simple way to assign a descriptor to a visual word is to search for nearest neighbors among the vocabulary.

Let $V = \{\omega_1, \ldots, \omega_n \}$ be the vocabulary, where $\omega_i \in \mathbb{R}^{d}$ (with $d$ the SIFT descriptor vector size, 128) and $n$ is the vocabulary size.

In \emph{hard assignment}, given and image with $X = \{x_1, ..., \x_p\}$ extracted local features, each local feature $x_i \in \mathbb{R}^{d}$ is assigned to one and only one codeword of the vocabulary. The assigned codeword index, $u_i$, is obtained with

$$u_i = arg \min_{j = 1, \ldots, n} ||x_i - \omega_j||$$

As result we obtain an index vector that associate each local feature with its closest codeword of the vocabulary.

